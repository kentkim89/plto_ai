import streamlit as st
import pandas as pd
import io
import numpy as np
import openpyxl
from openpyxl.styles import PatternFill, Border, Side, Alignment
from datetime import datetime
import requests
from urllib.parse import urlparse

# --------------------------------------------------------------------------
# í˜ì´ì§€ ì„¤ì •
# --------------------------------------------------------------------------
st.set_page_config(
    page_title="ì£¼ë¬¸ ì²˜ë¦¬ ìë™í™” v2.0",
    layout="wide",
    page_icon="ğŸ“Š"
)

# --------------------------------------------------------------------------
# SharePoint ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
# --------------------------------------------------------------------------

@st.cache_data(ttl=600)  # 10ë¶„ ìºì‹œ
def load_master_data_from_sharepoint():
    """SharePoint URLì—ì„œ ì§ì ‘ ë§ˆìŠ¤í„° ë°ì´í„° ë¡œë“œ"""
    try:
        # Streamlit secretsì—ì„œ SharePoint URL ê°€ì ¸ì˜¤ê¸°
        if "sharepoint_files" not in st.secrets:
            st.error("SharePoint ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤. secrets.toml íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
            return pd.DataFrame()
        
        file_url = st.secrets["sharepoint_files"]["plto_master_data_file_url"]
        
        # SharePoint ê³µìœ  ë§í¬ë¥¼ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ ë§í¬ë¡œ ë³€í™˜
        # SharePoint ë§í¬ í˜•ì‹: https://goremi.sharepoint.com/:x:/s/data/...
        # ë‹¤ìš´ë¡œë“œ ë§í¬ í˜•ì‹: https://goremi.sharepoint.com/sites/data/_layouts/15/download.aspx?share=...
        
        if "sharepoint.com/:x:" in file_url:
            # ê³µìœ  ë§í¬ì—ì„œ share ID ì¶”ì¶œ
            parts = file_url.split('/')
            share_id = parts[-1].split('?')[0]
            base_url = file_url.split('/:x:')[0]
            site_path = "/sites/data"
            download_url = f"{base_url}{site_path}/_layouts/15/download.aspx?share={share_id}"
        else:
            # ì´ë¯¸ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ ë§í¬ì¸ ê²½ìš°
            download_url = file_url
        
        # íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        response = requests.get(download_url, timeout=30)
        response.raise_for_status()
        
        # Excel íŒŒì¼ ì½ê¸°
        df_master = pd.read_excel(io.BytesIO(response.content))
        df_master = df_master.drop_duplicates(subset=['SKUì½”ë“œ'], keep='first')
        
        st.success("âœ… SharePointì—ì„œ ë§ˆìŠ¤í„° ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
        return df_master
        
    except Exception as e:
        st.error(f"âŒ SharePoint ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # ëŒ€ì²´ ë°©ë²•: ì‚¬ìš©ìê°€ ì§ì ‘ ì—…ë¡œë“œ
        st.warning("SharePoint ì—°ê²° ì‹¤íŒ¨. ë§ˆìŠ¤í„° ë°ì´í„°ë¥¼ ì§ì ‘ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return pd.DataFrame()

# --------------------------------------------------------------------------
# ê¸°ì¡´ ì²˜ë¦¬ í•¨ìˆ˜ë“¤
# --------------------------------------------------------------------------

def to_excel_formatted(df, format_type=None):
    """ë°ì´í„°í”„ë ˆì„ì„ ì„œì‹ì´ ì ìš©ëœ ì—‘ì…€ íŒŒì¼ë¡œ ë³€í™˜"""
    output = io.BytesIO()
    df_to_save = df.fillna('')
    
    if format_type == 'ecount_upload':
        df_to_save = df_to_save.rename(columns={'ì ìš”_ì „í‘œ': 'ì ìš”', 'ì ìš”_í’ˆëª©': 'ì ìš”.1'})

    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df_to_save.to_excel(writer, index=False, sheet_name='Sheet1')
    
    output.seek(0)
    workbook = openpyxl.load_workbook(output)
    sheet = workbook.active

    # ê°€ìš´ë° ì •ë ¬
    center_alignment = Alignment(horizontal='center', vertical='center')
    for row in sheet.iter_rows():
        for cell in row:
            cell.alignment = center_alignment

    # ì—´ ë„ˆë¹„ ìë™ ì¡°ì •
    for column_cells in sheet.columns:
        max_length = 0
        column = column_cells[0].column_letter
        for cell in column_cells:
            try:
                if cell.value and len(str(cell.value)) > max_length:
                    max_length = len(str(cell.value))
            except:
                pass
        adjusted_width = min((max_length + 2) * 1.2, 50)
        sheet.column_dimensions[column].width = adjusted_width
    
    # í…Œë‘ë¦¬ì™€ ìƒ‰ìƒ
    thin_border = Border(
        left=Side(style='thin'), 
        right=Side(style='thin'), 
        top=Side(style='thin'), 
        bottom=Side(style='thin')
    )
    pink_fill = PatternFill(start_color="FFEBEE", end_color="FFEBEE", fill_type="solid")

    if format_type == 'packing_list':
        for row in sheet.iter_rows(min_row=1, max_row=sheet.max_row):
            for cell in row:
                cell.border = thin_border
        
        bundle_start_row = 2
        for row_num in range(2, sheet.max_row + 2):
            current_bundle_cell = sheet.cell(row=row_num, column=1) if row_num <= sheet.max_row else None
            
            if (current_bundle_cell and current_bundle_cell.value) or (row_num > sheet.max_row):
                if row_num > 2:
                    bundle_end_row = row_num - 1
                    prev_bundle_num_str = str(sheet.cell(row=bundle_start_row, column=1).value)
                    
                    if prev_bundle_num_str.isdigit() and int(prev_bundle_num_str) % 2 != 0:
                        for r in range(bundle_start_row, bundle_end_row + 1):
                            for c in range(1, sheet.max_column + 1):
                                sheet.cell(row=r, column=c).fill = pink_fill
                    
                    if bundle_start_row < bundle_end_row:
                        sheet.merge_cells(
                            start_row=bundle_start_row, start_column=1,
                            end_row=bundle_end_row, end_column=1
                        )
                        sheet.merge_cells(
                            start_row=bundle_start_row, start_column=4,
                            end_row=bundle_end_row, end_column=4
                        )
                
                bundle_start_row = row_num

    elif format_type == 'quantity_summary':
        for row_idx, row in enumerate(sheet.iter_rows(min_row=1, max_row=sheet.max_row)):
            for cell in row:
                cell.border = thin_border
            if row_idx > 0 and row_idx % 2 != 0:
                for cell in row:
                    cell.fill = pink_fill
    
    final_output = io.BytesIO()
    workbook.save(final_output)
    final_output.seek(0)
    
    return final_output.getvalue()

def process_all_files(file1, file2, file3, df_master):
    """ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜"""
    try:
        # íŒŒì¼ ì½ê¸°
        df_smartstore = pd.read_excel(file1)
        df_ecount_orig = pd.read_excel(file2)
        df_godomall = pd.read_excel(file3)

        df_ecount_orig['original_order'] = range(len(df_ecount_orig))
        
        # ì»¬ëŸ¼ëª… í˜¸í™˜ì„± ì²˜ë¦¬
        if 'íšŒ í• ì¸ ê¸ˆì•¡' in df_godomall.columns:
            df_godomall.rename(columns={'íšŒ í• ì¸ ê¸ˆì•¡': 'íšŒì› í• ì¸ ê¸ˆì•¡'}, inplace=True)
        if 'ìì²´ì˜µì…˜ì½”ë“œ' in df_godomall.columns:
            df_godomall.rename(columns={'ìì²´ì˜µì…˜ì½”ë“œ': 'ì¬ê³ ê´€ë¦¬ì½”ë“œ'}, inplace=True)
        
        # ë°ì´í„° í´ë¦¬ë‹
        cols_to_numeric = ['ìƒí’ˆë³„ í’ˆëª©ê¸ˆì•¡', 'ì´ ë°°ì†¡ ê¸ˆì•¡', 'íšŒì› í• ì¸ ê¸ˆì•¡', 
                          'ì¿ í° í• ì¸ ê¸ˆì•¡', 'ì‚¬ìš©ëœ ë§ˆì¼ë¦¬ì§€', 'ì´ ê²°ì œ ê¸ˆì•¡']
        for col in cols_to_numeric:
            if col in df_godomall.columns:
                df_godomall[col] = pd.to_numeric(
                    df_godomall[col].astype(str).str.replace('[ì›,]', '', regex=True),
                    errors='coerce'
                ).fillna(0)
        
        # ë°°ì†¡ë¹„ ì¤‘ë³µ ë°©ì§€
        df_godomall['ë³´ì •ëœ_ë°°ì†¡ë¹„'] = np.where(
            df_godomall.duplicated(subset=['ìˆ˜ì·¨ì¸ ì´ë¦„']),
            0,
            df_godomall['ì´ ë°°ì†¡ ê¸ˆì•¡']
        )
        
        df_godomall['ìˆ˜ì •ë _ê¸ˆì•¡_ê³ ë„ëª°'] = (
            df_godomall['ìƒí’ˆë³„ í’ˆëª©ê¸ˆì•¡'] + df_godomall['ë³´ì •ëœ_ë°°ì†¡ë¹„'] -
            df_godomall['íšŒì› í• ì¸ ê¸ˆì•¡'] - df_godomall['ì¿ í° í• ì¸ ê¸ˆì•¡'] -
            df_godomall['ì‚¬ìš©ëœ ë§ˆì¼ë¦¬ì§€']
        )
        
        # ê²½ê³  ë©”ì‹œì§€ ìˆ˜ì§‘
        warnings = []
        
        # ê³ ë„ëª° ê¸ˆì•¡ ê²€ì¦
        for name, group in df_godomall.groupby('ìˆ˜ì·¨ì¸ ì´ë¦„'):
            calculated = group['ìˆ˜ì •ë _ê¸ˆì•¡_ê³ ë„ëª°'].sum()
            actual = group['ì´ ê²°ì œ ê¸ˆì•¡'].iloc[0]
            diff = calculated - actual
            if abs(diff) > 1:
                warnings.append(f"- [ê¸ˆì•¡ ë¶ˆì¼ì¹˜] {name}ë‹˜: {diff:,.0f}ì› ì°¨ì´")

        # ë©”ì¸ ë°ì´í„° ì²˜ë¦¬
        df_final = df_ecount_orig.copy().rename(columns={'ê¸ˆì•¡': 'ì‹¤ê²°ì œê¸ˆì•¡'})
        
        # ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ë³‘í•©
        key_cols = ['ì¬ê³ ê´€ë¦¬ì½”ë“œ', 'ì£¼ë¬¸ìˆ˜ëŸ‰', 'ìˆ˜ë ¹ìëª…']
        smartstore_prices = df_smartstore.rename(
            columns={'ì‹¤ê²°ì œê¸ˆì•¡': 'ìˆ˜ì •ë _ê¸ˆì•¡_ìŠ¤í† ì–´'}
        )[key_cols + ['ìˆ˜ì •ë _ê¸ˆì•¡_ìŠ¤í† ì–´']].drop_duplicates(subset=key_cols, keep='first')
        
        # ê³ ë„ëª° ë³‘í•©
        godomall_prices = df_godomall.rename(
            columns={'ìˆ˜ì·¨ì¸ ì´ë¦„': 'ìˆ˜ë ¹ìëª…', 'ìƒí’ˆìˆ˜ëŸ‰': 'ì£¼ë¬¸ìˆ˜ëŸ‰'}
        )[['ì¬ê³ ê´€ë¦¬ì½”ë“œ', 'ìˆ˜ë ¹ìëª…', 'ì£¼ë¬¸ìˆ˜ëŸ‰', 'ìˆ˜ì •ë _ê¸ˆì•¡_ê³ ë„ëª°']].drop_duplicates(
            subset=['ì¬ê³ ê´€ë¦¬ì½”ë“œ', 'ìˆ˜ë ¹ìëª…', 'ì£¼ë¬¸ìˆ˜ëŸ‰'], keep='first'
        )
        
        # ë°ì´í„° íƒ€ì… í†µì¼
        for col in ['ì¬ê³ ê´€ë¦¬ì½”ë“œ', 'ìˆ˜ë ¹ìëª…']:
            df_final[col] = df_final[col].astype(str).str.strip()
            smartstore_prices[col] = smartstore_prices[col].astype(str).str.strip()
            godomall_prices[col] = godomall_prices[col].astype(str).str.strip()
        
        df_final['ì£¼ë¬¸ìˆ˜ëŸ‰'] = pd.to_numeric(df_final['ì£¼ë¬¸ìˆ˜ëŸ‰'], errors='coerce').fillna(0).astype(int)
        smartstore_prices['ì£¼ë¬¸ìˆ˜ëŸ‰'] = pd.to_numeric(smartstore_prices['ì£¼ë¬¸ìˆ˜ëŸ‰'], errors='coerce').fillna(0).astype(int)
        godomall_prices['ì£¼ë¬¸ìˆ˜ëŸ‰'] = pd.to_numeric(godomall_prices['ì£¼ë¬¸ìˆ˜ëŸ‰'], errors='coerce').fillna(0).astype(int)
        
        df_final['ì‹¤ê²°ì œê¸ˆì•¡'] = pd.to_numeric(df_final['ì‹¤ê²°ì œê¸ˆì•¡'], errors='coerce').fillna(0).astype(int)
        
        # ë³‘í•©
        df_final = pd.merge(df_final, smartstore_prices, on=key_cols, how='left')
        df_final = pd.merge(df_final, godomall_prices, on=key_cols, how='left')

        # ê¸ˆì•¡ ì—…ë°ì´íŠ¸
        df_final['ì‹¤ê²°ì œê¸ˆì•¡'] = np.where(
            df_final['ì‡¼í•‘ëª°'] == 'ê³ ë„ëª°5',
            df_final['ìˆ˜ì •ë _ê¸ˆì•¡_ê³ ë„ëª°'].fillna(df_final['ì‹¤ê²°ì œê¸ˆì•¡']),
            df_final['ì‹¤ê²°ì œê¸ˆì•¡']
        )
        df_final['ì‹¤ê²°ì œê¸ˆì•¡'] = np.where(
            df_final['ì‡¼í•‘ëª°'] == 'ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´',
            df_final['ìˆ˜ì •ë _ê¸ˆì•¡_ìŠ¤í† ì–´'].fillna(df_final['ì‹¤ê²°ì œê¸ˆì•¡']),
            df_final['ì‹¤ê²°ì œê¸ˆì•¡']
        )
        
        # ê²°ê³¼ ë°ì´í„°í”„ë ˆì„
        df_main_result = df_final[[
            'ì¬ê³ ê´€ë¦¬ì½”ë“œ', 'SKUìƒí’ˆëª…', 'ì£¼ë¬¸ìˆ˜ëŸ‰', 'ì‹¤ê²°ì œê¸ˆì•¡', 
            'ì‡¼í•‘ëª°', 'ìˆ˜ë ¹ìëª…', 'original_order'
        ]]
        
        # ìˆ˜ëŸ‰ ìš”ì•½
        df_quantity_summary = df_main_result.groupby('SKUìƒí’ˆëª…', as_index=False)['ì£¼ë¬¸ìˆ˜ëŸ‰'].sum()
        df_quantity_summary.columns = ['SKUìƒí’ˆëª…', 'ê°œìˆ˜']
        
        # í¬ì¥ ë¦¬ìŠ¤íŠ¸
        df_packing = df_main_result.sort_values('original_order')[[
            'SKUìƒí’ˆëª…', 'ì£¼ë¬¸ìˆ˜ëŸ‰', 'ìˆ˜ë ¹ìëª…', 'ì‡¼í•‘ëª°'
        ]].copy()
        
        is_first = df_packing['ìˆ˜ë ¹ìëª…'] != df_packing['ìˆ˜ë ¹ìëª…'].shift(1)
        df_packing['ë¬¶ìŒë²ˆí˜¸'] = is_first.cumsum()
        df_packing_list = df_packing.copy()
        df_packing_list['ë¬¶ìŒë²ˆí˜¸'] = df_packing_list['ë¬¶ìŒë²ˆí˜¸'].where(is_first, '')
        df_packing_list = df_packing_list[[
            'ë¬¶ìŒë²ˆí˜¸', 'SKUìƒí’ˆëª…', 'ì£¼ë¬¸ìˆ˜ëŸ‰', 'ìˆ˜ë ¹ìëª…', 'ì‡¼í•‘ëª°'
        ]]

        # ì´ì¹´ìš´íŠ¸ ë°ì´í„° ìƒì„±
        df_merged = pd.merge(
            df_main_result,
            df_master[['SKUì½”ë“œ', 'ê³¼ì„¸ì—¬ë¶€', 'ì…ìˆ˜ëŸ‰']],
            left_on='ì¬ê³ ê´€ë¦¬ì½”ë“œ',
            right_on='SKUì½”ë“œ',
            how='left'
        )
        
        # ë¯¸ë“±ë¡ ìƒí’ˆ ê²½ê³ 
        for _, row in df_merged[df_merged['SKUì½”ë“œ'].isna()].iterrows():
            warnings.append(f"- [ë¯¸ë“±ë¡] {row['ì¬ê³ ê´€ë¦¬ì½”ë“œ']}: {row['SKUìƒí’ˆëª…']}")

        # ê±°ë˜ì²˜ ë§¤í•‘
        client_map = {
            'ì¿ íŒ¡': 'ì¿ íŒ¡ ì£¼ì‹íšŒì‚¬',
            'ê³ ë„ëª°5': 'ê³ ë˜ë¯¸ìì‚¬ëª°_í˜„ê¸ˆì˜ìˆ˜ì¦(ê³ ë„ëª°)',
            'ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´': 'ìŠ¤í† ì–´íŒœ',
            'ë°°ë¯¼ìƒíšŒ': 'ì£¼ì‹íšŒì‚¬ ìš°ì•„í•œí˜•ì œë“¤(ë°°ë¯¼ìƒíšŒ)',
            'ì´ì§€ì›°ëª°': 'ì£¼ì‹íšŒì‚¬ í˜„ëŒ€ì´ì§€ì›°'
        }
        
        # ì´ì¹´ìš´íŠ¸ ì—…ë¡œë“œ ë°ì´í„°
        df_ecount = pd.DataFrame()
        df_ecount['ì¼ì'] = datetime.now().strftime("%Y%m%d")
        df_ecount['ê±°ë˜ì²˜ëª…'] = df_merged['ì‡¼í•‘ëª°'].map(client_map).fillna(df_merged['ì‡¼í•‘ëª°'])
        df_ecount['ì¶œí•˜ì°½ê³ '] = 'ê³ ë˜ë¯¸'
        df_ecount['ê±°ë˜ìœ í˜•'] = np.where(df_merged['ê³¼ì„¸ì—¬ë¶€'] == 'ë©´ì„¸', 12, 11)
        df_ecount['ì ìš”_ì „í‘œ'] = 'ì˜¤ì „/ì˜¨ë¼ì¸'
        df_ecount['í’ˆëª©ì½”ë“œ'] = df_merged['ì¬ê³ ê´€ë¦¬ì½”ë“œ']
        
        # ìˆ˜ëŸ‰ ê³„ì‚°
        is_box = df_merged['SKUìƒí’ˆëª…'].str.contains("BOX", na=False)
        ì…ìˆ˜ëŸ‰ = pd.to_numeric(df_merged['ì…ìˆ˜ëŸ‰'], errors='coerce').fillna(1)
        base_qty = np.where(is_box, df_merged['ì£¼ë¬¸ìˆ˜ëŸ‰'] * ì…ìˆ˜ëŸ‰, df_merged['ì£¼ë¬¸ìˆ˜ëŸ‰'])
        is_3pack = df_merged['SKUìƒí’ˆëª…'].str.contains("3ê°œì…|3ê°œ", na=False)
        final_qty = np.where(is_3pack, base_qty * 3, base_qty)
        
        df_ecount['ë°•ìŠ¤'] = np.where(is_box, df_merged['ì£¼ë¬¸ìˆ˜ëŸ‰'], np.nan)
        df_ecount['ìˆ˜ëŸ‰'] = final_qty.astype(int)
        
        # ê¸ˆì•¡ ê³„ì‚°
        df_merged['ì‹¤ê²°ì œê¸ˆì•¡'] = pd.to_numeric(df_merged['ì‹¤ê²°ì œê¸ˆì•¡'], errors='coerce').fillna(0)
        ê³µê¸‰ê°€ì•¡ = np.where(
            df_merged['ê³¼ì„¸ì—¬ë¶€'] == 'ê³¼ì„¸',
            df_merged['ì‹¤ê²°ì œê¸ˆì•¡'] / 1.1,
            df_merged['ì‹¤ê²°ì œê¸ˆì•¡']
        )
        df_ecount['ê³µê¸‰ê°€ì•¡'] = ê³µê¸‰ê°€ì•¡
        df_ecount['ë¶€ê°€ì„¸'] = df_merged['ì‹¤ê²°ì œê¸ˆì•¡'] - df_ecount['ê³µê¸‰ê°€ì•¡']
        
        df_ecount['ì‡¼í•‘ëª°ê³ ê°ëª…'] = df_merged['ìˆ˜ë ¹ìëª…']
        df_ecount['original_order'] = df_merged['original_order']
        
        # ì»¬ëŸ¼ ì •ë¦¬
        ecount_columns = [
            'ì¼ì', 'ìˆœë²ˆ', 'ê±°ë˜ì²˜ì½”ë“œ', 'ê±°ë˜ì²˜ëª…', 'ë‹´ë‹¹ì', 'ì¶œí•˜ì°½ê³ ', 
            'ê±°ë˜ìœ í˜•', 'í†µí™”', 'í™˜ìœ¨', 'ì ìš”_ì „í‘œ', 'ë¯¸ìˆ˜ê¸ˆ', 'ì´í•©ê³„', 
            'ì—°ê²°ì „í‘œ', 'í’ˆëª©ì½”ë“œ', 'í’ˆëª©ëª…', 'ê·œê²©', 'ë°•ìŠ¤', 'ìˆ˜ëŸ‰', 
            'ë‹¨ê°€', 'ì™¸í™”ê¸ˆì•¡', 'ê³µê¸‰ê°€ì•¡', 'ë¶€ê°€ì„¸', 'ì ìš”_í’ˆëª©', 
            'ìƒì‚°ì „í‘œìƒì„±', 'ì‹œë¦¬ì–¼/ë¡œíŠ¸', 'ê´€ë¦¬í•­ëª©', 'ì‡¼í•‘ëª°ê³ ê°ëª…'
        ]
        
        for col in ecount_columns:
            if col not in df_ecount:
                df_ecount[col] = ''
        
        df_ecount['ê³µê¸‰ê°€ì•¡'] = df_ecount['ê³µê¸‰ê°€ì•¡'].round().astype('Int64')
        df_ecount['ë¶€ê°€ì„¸'] = df_ecount['ë¶€ê°€ì„¸'].round().astype('Int64')
        df_ecount['ê±°ë˜ìœ í˜•'] = pd.to_numeric(df_ecount['ê±°ë˜ìœ í˜•'])
        
        # ì •ë ¬
        sort_order = [
            'ê³ ë˜ë¯¸ìì‚¬ëª°_í˜„ê¸ˆì˜ìˆ˜ì¦(ê³ ë„ëª°)',
            'ìŠ¤í† ì–´íŒœ',
            'ì¿ íŒ¡ ì£¼ì‹íšŒì‚¬',
            'ì£¼ì‹íšŒì‚¬ ìš°ì•„í•œí˜•ì œë“¤(ë°°ë¯¼ìƒíšŒ)',
            'ì£¼ì‹íšŒì‚¬ í˜„ëŒ€ì´ì§€ì›°'
        ]
        
        df_ecount['ê±°ë˜ì²˜ëª…_sort'] = pd.Categorical(
            df_ecount['ê±°ë˜ì²˜ëª…'],
            categories=sort_order,
            ordered=True
        )
        
        df_ecount = df_ecount.sort_values(
            by=['ê±°ë˜ì²˜ëª…_sort', 'ê±°ë˜ìœ í˜•', 'original_order']
        ).drop(columns=['ê±°ë˜ì²˜ëª…_sort', 'original_order'])
        
        df_ecount_upload = df_ecount[ecount_columns]

        return (
            df_main_result.drop(columns=['original_order']),
            df_quantity_summary,
            df_packing_list,
            df_ecount_upload,
            True,
            "âœ… ëª¨ë“  ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!",
            warnings
        )

    except Exception as e:
        import traceback
        return None, None, None, None, False, f"âŒ ì˜¤ë¥˜: {str(e)}\n{traceback.format_exc()}", []

# --------------------------------------------------------------------------
# ë©”ì¸ ì•±
# --------------------------------------------------------------------------

st.title("ğŸ“Š ì£¼ë¬¸ ì²˜ë¦¬ ìë™í™” ì‹œìŠ¤í…œ v2.0")
st.markdown("### SharePoint ì—°ë™ ë²„ì „")
st.markdown("---")

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ğŸ“Œ ìƒíƒœ")
    
    # SharePoint ì—°ê²° ìƒíƒœ ì²´í¬
    if "sharepoint_files" in st.secrets:
        st.success("âœ… SharePoint ì„¤ì • ì™„ë£Œ")
    else:
        st.error("âŒ SharePoint ë¯¸ì„¤ì •")
        st.info("secrets.toml íŒŒì¼ ì„¤ì • í•„ìš”")
    
    # ìºì‹œ ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ğŸ”„ ìºì‹œ ì´ˆê¸°í™”"):
        st.cache_data.clear()
        st.success("ìºì‹œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.rerun()
    
    st.markdown("---")
    st.caption("Â© 2024 PLTO System")

# íƒ­ ìƒì„±
tab1, tab2, tab3 = st.tabs(["ğŸ“‘ ì£¼ë¬¸ ì²˜ë¦¬", "ğŸ“ˆ í†µê³„", "âš™ï¸ ì„¤ì •"])

with tab1:
    st.header("ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ")
    
    # ë§ˆìŠ¤í„° ë°ì´í„° ë¡œë“œ ì„¹ì…˜
    with st.expander("ğŸ“Š ë§ˆìŠ¤í„° ë°ì´í„° ìƒíƒœ", expanded=True):
        if st.button("ğŸ”„ SharePointì—ì„œ ë§ˆìŠ¤í„° ë°ì´í„° ìƒˆë¡œê³ ì¹¨"):
            st.cache_data.clear()
            
        df_master = load_master_data_from_sharepoint()
        
        if not df_master.empty:
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ì´ SKU", f"{len(df_master):,}ê°œ")
            with col2:
                st.metric("ê³¼ì„¸ ìƒí’ˆ", f"{len(df_master[df_master['ê³¼ì„¸ì—¬ë¶€']=='ê³¼ì„¸']):,}ê°œ")
            with col3:
                st.metric("ë©´ì„¸ ìƒí’ˆ", f"{len(df_master[df_master['ê³¼ì„¸ì—¬ë¶€']=='ë©´ì„¸']):,}ê°œ")
        else:
            st.warning("âš ï¸ ë§ˆìŠ¤í„° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ì—…ë¡œë“œí•˜ì„¸ìš”.")
            manual_master = st.file_uploader("ë§ˆìŠ¤í„° ë°ì´í„° ì—…ë¡œë“œ", type=['xlsx', 'xls', 'csv'], key="master")
            if manual_master:
                try:
                    if manual_master.name.endswith('.csv'):
                        df_master = pd.read_csv(manual_master)
                    else:
                        df_master = pd.read_excel(manual_master)
                    df_master = df_master.drop_duplicates(subset=['SKUì½”ë“œ'], keep='first')
                    st.success(f"âœ… ë§ˆìŠ¤í„° ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df_master)}ê°œ SKU")
                except Exception as e:
                    st.error(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
    
    st.markdown("---")
    
    # ì£¼ë¬¸ íŒŒì¼ ì—…ë¡œë“œ
    col1, col2, col3 = st.columns(3)
    with col1:
        file1 = st.file_uploader("ğŸ“± ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´", type=['xlsx', 'xls'], key="smart")
    with col2:
        file2 = st.file_uploader("ğŸ“‹ ì´ì¹´ìš´íŠ¸", type=['xlsx', 'xls'], key="ecount")
    with col3:
        file3 = st.file_uploader("ğŸª ê³ ë„ëª°", type=['xlsx', 'xls'], key="godo")
    
    # ì²˜ë¦¬ ë²„íŠ¼
    if st.button("ğŸš€ ì²˜ë¦¬ ì‹œì‘", type="primary", use_container_width=True):
        if file1 and file2 and file3:
            if not df_master.empty:
                # íŒŒì¼ ì²˜ë¦¬
                with st.spinner('ë°ì´í„° ì²˜ë¦¬ ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.'):
                    result = process_all_files(file1, file2, file3, df_master)
                    df_main, df_qty, df_pack, df_ecount, success, message, warnings = result
                
                if success:
                    st.balloons()
                    st.success(message)
                    
                    # ê²½ê³  í‘œì‹œ
                    if warnings:
                        with st.expander(f"âš ï¸ í™•ì¸ í•„ìš” í•­ëª© ({len(warnings)}ê±´)", expanded=True):
                            for w in warnings:
                                st.write(w)
                    
                    # ê²°ê³¼ ì €ì¥
                    st.session_state['result'] = {
                        'main': df_main,
                        'qty': df_qty,
                        'pack': df_pack,
                        'ecount': df_ecount
                    }
                    
                    # ë‹¤ìš´ë¡œë“œ ì„¹ì…˜
                    st.markdown("---")
                    st.subheader("ğŸ“¥ ë‹¤ìš´ë¡œë“œ")
                    
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.download_button(
                            "ğŸ’¼ ì´ì¹´ìš´íŠ¸",
                            to_excel_formatted(df_ecount, 'ecount_upload'),
                            f"ì´ì¹´ìš´íŠ¸_{timestamp}.xlsx",
                            mime="application/vnd.ms-excel",
                            use_container_width=True
                        )
                    
                    with col2:
                        st.download_button(
                            "ğŸ“¦ í¬ì¥ë¦¬ìŠ¤íŠ¸",
                            to_excel_formatted(df_pack, 'packing_list'),
                            f"í¬ì¥_{timestamp}.xlsx",
                            mime="application/vnd.ms-excel",
                            use_container_width=True
                        )
                    
                    with col3:
                        st.download_button(
                            "ğŸ“Š ìˆ˜ëŸ‰ìš”ì•½",
                            to_excel_formatted(df_qty, 'quantity_summary'),
                            f"ìˆ˜ëŸ‰_{timestamp}.xlsx",
                            mime="application/vnd.ms-excel",
                            use_container_width=True
                        )
                    
                    with col4:
                        st.download_button(
                            "âœ… ìµœì¢…ê²°ê³¼",
                            to_excel_formatted(df_main),
                            f"ê²°ê³¼_{timestamp}.xlsx",
                            mime="application/vnd.ms-excel",
                            use_container_width=True
                        )
                    
                    # ë¯¸ë¦¬ë³´ê¸°
                    st.markdown("---")
                    st.subheader("ğŸ“‹ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
                    
                    preview_option = st.selectbox(
                        "í™•ì¸í•  ë°ì´í„° ì„ íƒ",
                        ["ì´ì¹´ìš´íŠ¸ ì—…ë¡œë“œ", "í¬ì¥ ë¦¬ìŠ¤íŠ¸", "ìˆ˜ëŸ‰ ìš”ì•½", "ìµœì¢… ê²°ê³¼"]
                    )
                    
                    if preview_option == "ì´ì¹´ìš´íŠ¸ ì—…ë¡œë“œ":
                        st.dataframe(df_ecount, use_container_width=True)
                    elif preview_option == "í¬ì¥ ë¦¬ìŠ¤íŠ¸":
                        st.dataframe(df_pack, use_container_width=True)
                    elif preview_option == "ìˆ˜ëŸ‰ ìš”ì•½":
                        st.dataframe(df_qty, use_container_width=True)
                    else:
                        st.dataframe(df_main, use_container_width=True)
                    
                else:
                    st.error(message)
            else:
                st.error("âŒ ë§ˆìŠ¤í„° ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤!")
        else:
            st.warning("âš ï¸ 3ê°œ íŒŒì¼ì„ ëª¨ë‘ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")

with tab2:
    st.header("ğŸ“Š í†µê³„ ë¶„ì„")
    
    if 'result' in st.session_state:
        df = st.session_state['result']['main']
        
        # ê¸°ë³¸ ë©”íŠ¸ë¦­
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            total_revenue = df['ì‹¤ê²°ì œê¸ˆì•¡'].sum()
            st.metric("ğŸ’° ì´ ë§¤ì¶œ", f"â‚©{total_revenue:,.0f}")
        
        with col2:
            total_orders = len(df)
            st.metric("ğŸ“¦ ì´ ì£¼ë¬¸ìˆ˜", f"{total_orders:,}")
        
        with col3:
            avg_order = total_revenue / total_orders if total_orders > 0 else 0
            st.metric("ğŸ’µ í‰ê·  ì£¼ë¬¸ì•¡", f"â‚©{avg_order:,.0f}")
        
        with col4:
            unique_customers = df['ìˆ˜ë ¹ìëª…'].nunique()
            st.metric("ğŸ‘¥ ê³ ê°ìˆ˜", f"{unique_customers:,}")
        
        st.markdown("---")
        
        # ì±„ë„ë³„ ë¶„ì„
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ›’ ì±„ë„ë³„ ë§¤ì¶œ")
            channel_stats = df.groupby('ì‡¼í•‘ëª°')['ì‹¤ê²°ì œê¸ˆì•¡'].sum().sort_values(ascending=True)
            st.bar_chart(channel_stats)
            
            # ìƒì„¸ í…Œì´ë¸”
            channel_detail = df.groupby('ì‡¼í•‘ëª°').agg({
                'ì‹¤ê²°ì œê¸ˆì•¡': 'sum',
                'ì£¼ë¬¸ìˆ˜ëŸ‰': 'sum',
                'ìˆ˜ë ¹ìëª…': 'nunique'
            }).round(0)
            channel_detail.columns = ['ë§¤ì¶œì•¡', 'íŒë§¤ìˆ˜ëŸ‰', 'ê³ ê°ìˆ˜']
            st.dataframe(channel_detail, use_container_width=True)
        
        with col2:
            st.subheader("ğŸ† TOP 10 ìƒí’ˆ")
            top_products = df.groupby('SKUìƒí’ˆëª…')['ì£¼ë¬¸ìˆ˜ëŸ‰'].sum().nlargest(10).sort_values(ascending=True)
            st.bar_chart(top_products)
            
            # ìƒì„¸ í…Œì´ë¸”
            product_detail = df.groupby('SKUìƒí’ˆëª…').agg({
                'ì£¼ë¬¸ìˆ˜ëŸ‰': 'sum',
                'ì‹¤ê²°ì œê¸ˆì•¡': 'sum'
            }).nlargest(10, 'ì£¼ë¬¸ìˆ˜ëŸ‰')
            product_detail.columns = ['íŒë§¤ìˆ˜ëŸ‰', 'ë§¤ì¶œì•¡']
            st.dataframe(product_detail, use_container_width=True)
        
    else:
        st.info("ğŸ“Œ ë¨¼ì € ì£¼ë¬¸ ì²˜ë¦¬ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")

with tab3:
    st.header("âš™ï¸ ì‹œìŠ¤í…œ ì„¤ì •")
    
    st.subheader("ğŸ“ SharePoint ì„¤ì •")
    
    if "sharepoint_files" in st.secrets:
        st.code(f"""
[sharepoint_files]
plto_master_data_file_url = "{st.secrets['sharepoint_files']['plto_master_data_file_url'][:50]}..."
site_name = "{st.secrets['sharepoint_files']['site_name']}"
file_name = "{st.secrets['sharepoint_files']['file_name']}"
        """)
        st.success("âœ… SharePoint ì„¤ì •ì´ ì •ìƒì ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    else:
        st.warning("âš ï¸ SharePoint ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.info("""
        Streamlit secrets.toml íŒŒì¼ì— ë‹¤ìŒê³¼ ê°™ì´ ì„¤ì •í•˜ì„¸ìš”:
        
        ```toml
        [sharepoint_files]
        plto_master_data_file_url = "SharePoint ê³µìœ  ë§í¬"
        site_name = "data"
        file_name = "plto_master_data.xlsx"
        ```
        """)
    
    st.markdown("---")
    
    st.subheader("ğŸ“ ì‚¬ìš© ë°©ë²•")
    st.markdown("""
    1. **ë§ˆìŠ¤í„° ë°ì´í„° í™•ì¸**: SharePointì—ì„œ ìë™ìœ¼ë¡œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤
    2. **íŒŒì¼ ì—…ë¡œë“œ**: ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´, ì´ì¹´ìš´íŠ¸, ê³ ë„ëª° íŒŒì¼ì„ ê°ê° ì—…ë¡œë“œ
    3. **ì²˜ë¦¬ ì‹¤í–‰**: 'ì²˜ë¦¬ ì‹œì‘' ë²„íŠ¼ í´ë¦­
    4. **ê²°ê³¼ ë‹¤ìš´ë¡œë“œ**: ìƒì„±ëœ 4ê°œì˜ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    5. **í†µê³„ í™•ì¸**: í†µê³„ íƒ­ì—ì„œ íŒë§¤ ë¶„ì„ í™•ì¸
    """)
    
    st.markdown("---")
    
    st.subheader("ğŸ”§ ë¬¸ì œ í•´ê²°")
    st.markdown("""
    - **SharePoint ì—°ê²° ì‹¤íŒ¨**: secrets.toml íŒŒì¼ í™•ì¸
    - **ë§ˆìŠ¤í„° ë°ì´í„° ì—†ìŒ**: ìˆ˜ë™ìœ¼ë¡œ ì—…ë¡œë“œ ê°€ëŠ¥
    - **ì²˜ë¦¬ ì˜¤ë¥˜**: íŒŒì¼ í˜•ì‹ê³¼ ì»¬ëŸ¼ëª… í™•ì¸
    - **ìºì‹œ ë¬¸ì œ**: ì‚¬ì´ë“œë°”ì˜ 'ìºì‹œ ì´ˆê¸°í™”' í´ë¦­
    """)
