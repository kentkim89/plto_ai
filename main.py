import streamlit as st
import pandas as pd
import io
import numpy as np
import openpyxl
from openpyxl.styles import PatternFill, Border, Side, Alignment
from openpyxl.utils import get_column_letter
from datetime import datetime, timedelta
import requests
import tempfile
import os
import plotly.express as px
import plotly.graph_objects as go
import google.generativeai as genai

# --------------------------------------------------------------------------
# Streamlit í˜ì´ì§€ ì„¤ì •
# --------------------------------------------------------------------------
st.set_page_config(
    page_title="ì£¼ë¬¸ ì²˜ë¦¬ ìë™í™” ì‹œìŠ¤í…œ v2.0", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# --------------------------------------------------------------------------
# SharePoint ê°„ë‹¨í•œ ì—°ê²° í•¨ìˆ˜ (Office365 ë¼ì´ë¸ŒëŸ¬ë¦¬ ì œê±°)
# --------------------------------------------------------------------------
@st.cache_data(ttl=600)  # 10ë¶„ ìºì‹œ
def load_master_from_sharepoint():
    """SharePointì—ì„œ ë§ˆìŠ¤í„° ë°ì´í„° ë¡œë“œ - ì§ì ‘ URL ë°©ì‹"""
    try:
        # SharePoint ì§ì ‘ ë‹¤ìš´ë¡œë“œ URLë¡œ ë³€í™˜
        share_url = st.secrets["sharepoint_files"]["plto_master_data_file_url"]
        
        # ê³µìœ  ë§í¬ë¥¼ ë‹¤ìš´ë¡œë“œ ë§í¬ë¡œ ë³€í™˜
        if "sharepoint.com/:x:" in share_url:
            # Excel ê³µìœ  ë§í¬ íŒ¨í„´
            file_id = share_url.split("/")[-1].split("?")[0]
            download_url = share_url.replace("/:x:/", "/_layouts/15/download.aspx?UniqueId=").split("?")[0]
        else:
            download_url = share_url
        
        # ì§ì ‘ ë‹¤ìš´ë¡œë“œ ì‹œë„
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        response = requests.get(share_url, headers=headers, allow_redirects=True)
        
        if response.status_code == 200:
            df_master = pd.read_excel(io.BytesIO(response.content))
            df_master = df_master.drop_duplicates(subset=['SKUì½”ë“œ'], keep='first')
            st.success(f"âœ… ë§ˆìŠ¤í„° ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df_master)}ê°œ í’ˆëª©")
            return df_master
        else:
            raise Exception(f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {response.status_code}")
            
    except Exception as e:
        st.warning(f"âš ï¸ SharePoint ì ‘ê·¼ ì‹¤íŒ¨: {e}")
        
        # ë¡œì»¬ íŒŒì¼ í´ë°±
        try:
            if os.path.exists("master_data.csv"):
                df_master = pd.read_csv("master_data.csv")
                df_master = df_master.drop_duplicates(subset=['SKUì½”ë“œ'], keep='first')
                st.info(f"ğŸ“ ë¡œì»¬ ë°±ì—… íŒŒì¼ ì‚¬ìš©: {len(df_master)}ê°œ í’ˆëª©")
                return df_master
            else:
                # ìƒ˜í”Œ ë°ì´í„° ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)
                st.warning("âš ï¸ ë§ˆìŠ¤í„° íŒŒì¼ì´ ì—†ì–´ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
                sample_data = {
                    'SKUì½”ë“œ': ['TEST001', 'TEST002', 'TEST003'],
                    'ê³¼ì„¸ì—¬ë¶€': ['ê³¼ì„¸', 'ë©´ì„¸', 'ê³¼ì„¸'],
                    'ì…ìˆ˜ëŸ‰': [1, 1, 1]
                }
                return pd.DataFrame(sample_data)
        except Exception as e2:
            st.error(f"ë¡œì»¬ íŒŒì¼ë„ ì‹¤íŒ¨: {e2}")
            return None

def save_record_locally(df_new_records):
    """ë¡œì»¬ì— ê¸°ë¡ ì €ì¥ (SharePoint ëŒ€ì‹  ì„ì‹œ ì‚¬ìš©)"""
    try:
        record_file = "plto_record_data.xlsx"
        
        # ê¸°ì¡´ íŒŒì¼ ë¡œë“œ ë˜ëŠ” ìƒˆë¡œ ìƒì„±
        if os.path.exists(record_file):
            df_existing = pd.read_excel(record_file)
        else:
            df_existing = pd.DataFrame()
        
        # í—¤ë” ì •ì˜
        expected_columns = [
            'ì²˜ë¦¬ì¼ì‹œ', 'ì£¼ë¬¸ì¼ì', 'ì‡¼í•‘ëª°', 'ê±°ë˜ì²˜ëª…', 'í’ˆëª©ì½”ë“œ', 'SKUìƒí’ˆëª…', 
            'ì£¼ë¬¸ìˆ˜ëŸ‰', 'ì‹¤ê²°ì œê¸ˆì•¡', 'ê³µê¸‰ê°€ì•¡', 'ë¶€ê°€ì„¸', 'ìˆ˜ë ¹ìëª…', 
            'ê³¼ì„¸ì—¬ë¶€', 'ê±°ë˜ìœ í˜•', 'ì²˜ë¦¬ì'
        ]
        
        if df_existing.empty:
            df_existing = pd.DataFrame(columns=expected_columns)
        
        # ìƒˆ ë ˆì½”ë“œ ì¤€ë¹„
        df_new_records['ì²˜ë¦¬ì¼ì‹œ'] = datetime.now()
        df_new_records['ì²˜ë¦¬ì'] = st.session_state.get('user_name', 'Unknown')
        
        # ì¤‘ë³µ ì²´í¬
        if not df_existing.empty and 'ì£¼ë¬¸ì¼ì' in df_existing.columns:
            merge_keys = ['ì£¼ë¬¸ì¼ì', 'ì‡¼í•‘ëª°', 'ìˆ˜ë ¹ìëª…', 'í’ˆëª©ì½”ë“œ']
            
            # ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
            keys_exist = all(key in df_existing.columns and key in df_new_records.columns for key in merge_keys)
            
            if keys_exist:
                df_existing['check_key'] = df_existing[merge_keys].astype(str).agg('_'.join, axis=1)
                df_new_records['check_key'] = df_new_records[merge_keys].astype(str).agg('_'.join, axis=1)
                
                new_keys = set(df_new_records['check_key']) - set(df_existing['check_key'])
                df_new_records = df_new_records[df_new_records['check_key'].isin(new_keys)]
                
                df_existing = df_existing.drop('check_key', axis=1, errors='ignore')
                df_new_records = df_new_records.drop('check_key', axis=1, errors='ignore')
        
        # ë°ì´í„° ê²°í•©
        df_combined = pd.concat([df_existing, df_new_records], ignore_index=True)
        
        # íŒŒì¼ ì €ì¥
        df_combined.to_excel(record_file, index=False)
        
        return True, len(df_new_records)
        
    except Exception as e:
        st.error(f"ê¸°ë¡ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False, 0

def load_record_data():
    """ë¡œì»¬ì—ì„œ ê¸°ë¡ ë°ì´í„° ë¡œë“œ"""
    try:
        record_file = "plto_record_data.xlsx"
        if os.path.exists(record_file):
            return pd.read_excel(record_file)
        else:
            return pd.DataFrame()
    except:
        return pd.DataFrame()

# --------------------------------------------------------------------------
# Gemini AI ë¶„ì„ í•¨ìˆ˜ (ê°„ì†Œí™”)
# --------------------------------------------------------------------------
def analyze_with_gemini(df_data, analysis_type="trend"):
    """Gemini AIë¥¼ ì‚¬ìš©í•œ ë°ì´í„° ë¶„ì„"""
    try:
        genai.configure(api_key=st.secrets["gemini"]["api_key"])
        model = genai.GenerativeModel('gemini-pro')
        
        if df_data.empty:
            return "ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        # ê°„ë‹¨í•œ ìš”ì•½ë§Œ ìƒì„±
        summary = f"""
        ì´ ì£¼ë¬¸: {len(df_data)}ê±´
        ì´ ë§¤ì¶œ: {df_data['ì‹¤ê²°ì œê¸ˆì•¡'].sum():,.0f}ì›
        í‰ê·  ì£¼ë¬¸: {df_data['ì‹¤ê²°ì œê¸ˆì•¡'].mean():,.0f}ì›
        """
        
        prompt = f"ë‹¤ìŒ íŒë§¤ ë°ì´í„°ë¥¼ ê°„ë‹¨íˆ ë¶„ì„í•´ì£¼ì„¸ìš” (í•œêµ­ì–´ë¡œ 3-5ë¬¸ì¥): {summary}"
        
        response = model.generate_content(prompt)
        return response.text
        
    except Exception as e:
        return f"AI ë¶„ì„ ì‹¤íŒ¨: {e}"

# --------------------------------------------------------------------------
# ê°„ë‹¨í•œ ëŒ€ì‹œë³´ë“œ
# --------------------------------------------------------------------------
def create_simple_dashboard(df_record):
    """ê°„ë‹¨í•œ ëŒ€ì‹œë³´ë“œ ìƒì„±"""
    if df_record.empty:
        st.warning("ğŸ“Š ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê¸°ë³¸ ë©”íŠ¸ë¦­
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        total_revenue = df_record['ì‹¤ê²°ì œê¸ˆì•¡'].sum()
        st.metric("ì´ ë§¤ì¶œ", f"â‚©{total_revenue:,.0f}")
    
    with col2:
        total_orders = len(df_record)
        st.metric("ì´ ì£¼ë¬¸ ìˆ˜", f"{total_orders:,}")
    
    with col3:
        avg_order = total_revenue / total_orders if total_orders > 0 else 0
        st.metric("í‰ê·  ì£¼ë¬¸", f"â‚©{avg_order:,.0f}")
    
    with col4:
        unique_customers = df_record['ìˆ˜ë ¹ìëª…'].nunique()
        st.metric("ê³ ê° ìˆ˜", f"{unique_customers:,}")
    
    # ê°„ë‹¨í•œ ì°¨íŠ¸
    if 'ì‡¼í•‘ëª°' in df_record.columns:
        mall_sales = df_record.groupby('ì‡¼í•‘ëª°')['ì‹¤ê²°ì œê¸ˆì•¡'].sum().reset_index()
        fig = px.pie(mall_sales, values='ì‹¤ê²°ì œê¸ˆì•¡', names='ì‡¼í•‘ëª°', title='ì‡¼í•‘ëª°ë³„ ë§¤ì¶œ')
        st.plotly_chart(fig, use_container_width=True)

# --------------------------------------------------------------------------
# ê¸°ì¡´ í•µì‹¬ í•¨ìˆ˜ë“¤ (ìœ ì§€)
# --------------------------------------------------------------------------
def to_excel_formatted(df, format_type=None):
    """ë°ì´í„°í”„ë ˆì„ì„ ì„œì‹ì´ ì ìš©ëœ ì—‘ì…€ íŒŒì¼ë¡œ ë³€í™˜"""
    output = io.BytesIO()
    df_to_save = df.fillna('')
    
    if format_type == 'ecount_upload':
        df_to_save = df_to_save.rename(columns={'ì ìš”_ì „í‘œ': 'ì ìš”', 'ì ìš”_í’ˆëª©': 'ì ìš”.1'})

    df_to_save.to_excel(output, index=False, sheet_name='Sheet1')
    
    workbook = openpyxl.load_workbook(output)
    sheet = workbook.active

    # ê³µí†µ ì„œì‹
    center_alignment = Alignment(horizontal='center', vertical='center')
    for row in sheet.iter_rows():
        for cell in row:
            cell.alignment = center_alignment

    # ì—´ ë„ˆë¹„ ìë™ ì¡°ì •
    for column_cells in sheet.columns:
        max_length = 0
        column = column_cells[0].column_letter
        for cell in column_cells:
            try:
                if cell.value and len(str(cell.value)) > max_length:
                    max_length = len(str(cell.value))
            except:
                pass
        adjusted_width = min((max_length + 2) * 1.2, 50)
        sheet.column_dimensions[column].width = adjusted_width
    
    thin_border = Border(left=Side(style='thin'), right=Side(style='thin'), 
                         top=Side(style='thin'), bottom=Side(style='thin'))
    pink_fill = PatternFill(start_color="FFEBEE", end_color="FFEBEE", fill_type="solid")

    if format_type == 'packing_list':
        for row in sheet.iter_rows(min_row=1, max_row=sheet.max_row):
            for cell in row:
                cell.border = thin_border
        
        # ë¬¶ìŒë²ˆí˜¸ ì²˜ë¦¬
        bundle_start_row = 2
        for row_num in range(2, sheet.max_row + 2):
            current_bundle_cell = sheet.cell(row=row_num, column=1) if row_num <= sheet.max_row else None
            
            if (current_bundle_cell and current_bundle_cell.value) or (row_num > sheet.max_row):
                if row_num > 2:
                    bundle_end_row = row_num - 1
                    prev_bundle_num_str = str(sheet.cell(row=bundle_start_row, column=1).value)
                    
                    if prev_bundle_num_str.isdigit() and int(prev_bundle_num_str) % 2 != 0:
                        for r in range(bundle_start_row, bundle_end_row + 1):
                            for c in range(1, sheet.max_column + 1):
                                sheet.cell(row=r, column=c).fill = pink_fill
                    
                    if bundle_start_row < bundle_end_row:
                        sheet.merge_cells(start_row=bundle_start_row, start_column=1, 
                                        end_row=bundle_end_row, end_column=1)
                        sheet.merge_cells(start_row=bundle_start_row, start_column=4, 
                                        end_row=bundle_end_row, end_column=4)
                
                bundle_start_row = row_num

    if format_type == 'quantity_summary':
        for row_idx, row in enumerate(sheet.iter_rows(min_row=1, max_row=sheet.max_row)):
            for cell in row:
                cell.border = thin_border
            if row_idx > 0 and row_idx % 2 != 0:
                for cell in row:
                    cell.fill = pink_fill
    
    final_output = io.BytesIO()
    workbook.save(final_output)
    final_output.seek(0)
    
    return final_output.getvalue()

def process_all_files(file1, file2, file3, df_master):
    """ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜"""
    try:
        df_smartstore = pd.read_excel(file1)
        df_ecount_orig = pd.read_excel(file2)
        df_godomall = pd.read_excel(file3)

        # ì£¼ë¬¸ì¼ì ì¶”ì¶œ
        order_date = datetime.now().date()
        if 'ì¼ì' in df_ecount_orig.columns:
            try:
                order_date = pd.to_datetime(df_ecount_orig['ì¼ì'].iloc[0], format='%Y%m%d', errors='coerce')
                if not pd.isna(order_date):
                    order_date = order_date.date()
            except:
                pass

        df_ecount_orig['original_order'] = range(len(df_ecount_orig))
        
        # ì»¬ëŸ¼ëª… í˜¸í™˜ì„± ì²˜ë¦¬
        if 'íšŒ í• ì¸ ê¸ˆì•¡' in df_godomall.columns:
            df_godomall.rename(columns={'íšŒ í• ì¸ ê¸ˆì•¡': 'íšŒì› í• ì¸ ê¸ˆì•¡'}, inplace=True)
        if 'ìì²´ì˜µì…˜ì½”ë“œ' in df_godomall.columns:
            df_godomall.rename(columns={'ìì²´ì˜µì…˜ì½”ë“œ': 'ì¬ê³ ê´€ë¦¬ì½”ë“œ'}, inplace=True)
        
        # ë°ì´í„° í´ë¦¬ë‹
        cols_to_numeric = ['ìƒí’ˆë³„ í’ˆëª©ê¸ˆì•¡', 'ì´ ë°°ì†¡ ê¸ˆì•¡', 'íšŒì› í• ì¸ ê¸ˆì•¡', 
                          'ì¿ í° í• ì¸ ê¸ˆì•¡', 'ì‚¬ìš©ëœ ë§ˆì¼ë¦¬ì§€', 'ì´ ê²°ì œ ê¸ˆì•¡']
        for col in cols_to_numeric:
            if col in df_godomall.columns: 
                df_godomall[col] = pd.to_numeric(
                    df_godomall[col].astype(str).str.replace('[ì›,]', '', regex=True), 
                    errors='coerce'
                ).fillna(0)
        
        # ë°°ì†¡ë¹„ ì¤‘ë³µ ê³„ì‚° ë°©ì§€
        df_godomall['ë³´ì •ëœ_ë°°ì†¡ë¹„'] = np.where(
            df_godomall.duplicated(subset=['ìˆ˜ì·¨ì¸ ì´ë¦„']), 
            0, 
            df_godomall['ì´ ë°°ì†¡ ê¸ˆì•¡']
        )
        
        df_godomall['ìˆ˜ì •ë _ê¸ˆì•¡_ê³ ë„ëª°'] = (
            df_godomall['ìƒí’ˆë³„ í’ˆëª©ê¸ˆì•¡'] + df_godomall['ë³´ì •ëœ_ë°°ì†¡ë¹„'] - 
            df_godomall['íšŒì› í• ì¸ ê¸ˆì•¡'] - df_godomall['ì¿ í° í• ì¸ ê¸ˆì•¡'] - 
            df_godomall['ì‚¬ìš©ëœ ë§ˆì¼ë¦¬ì§€']
        )
        
        # ê²½ê³  ë©”ì‹œì§€ ìˆ˜ì§‘
        warnings = []
        
        # ê¸°ë³¸ ì²˜ë¦¬
        df_final = df_ecount_orig.copy().rename(columns={'ê¸ˆì•¡': 'ì‹¤ê²°ì œê¸ˆì•¡'})
        
        # ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ë³‘í•©
        key_cols_smartstore = ['ì¬ê³ ê´€ë¦¬ì½”ë“œ', 'ì£¼ë¬¸ìˆ˜ëŸ‰', 'ìˆ˜ë ¹ìëª…']
        smartstore_prices = df_smartstore.rename(
            columns={'ì‹¤ê²°ì œê¸ˆì•¡': 'ìˆ˜ì •ë _ê¸ˆì•¡_ìŠ¤í† ì–´'}
        )[key_cols_smartstore + ['ìˆ˜ì •ë _ê¸ˆì•¡_ìŠ¤í† ì–´']].drop_duplicates(
            subset=key_cols_smartstore, keep='first'
        )
        
        # ê³ ë„ëª° ë³‘í•©
        key_cols_godomall = ['ì¬ê³ ê´€ë¦¬ì½”ë“œ', 'ìˆ˜ì·¨ì¸ ì´ë¦„', 'ìƒí’ˆìˆ˜ëŸ‰']
        godomall_prices = df_godomall[key_cols_godomall + ['ìˆ˜ì •ë _ê¸ˆì•¡_ê³ ë„ëª°']].rename(
            columns={'ìˆ˜ì·¨ì¸ ì´ë¦„': 'ìˆ˜ë ¹ìëª…', 'ìƒí’ˆìˆ˜ëŸ‰': 'ì£¼ë¬¸ìˆ˜ëŸ‰'}
        ).drop_duplicates(subset=['ì¬ê³ ê´€ë¦¬ì½”ë“œ', 'ìˆ˜ë ¹ìëª…', 'ì£¼ë¬¸ìˆ˜ëŸ‰'], keep='first')
        
        # ë°ì´í„° íƒ€ì… í†µì¼
        for col in ['ì¬ê³ ê´€ë¦¬ì½”ë“œ', 'ìˆ˜ë ¹ìëª…']:
            df_final[col] = df_final[col].astype(str).str.strip()
            smartstore_prices[col] = smartstore_prices[col].astype(str).str.strip()
            godomall_prices[col] = godomall_prices[col].astype(str).str.strip()
        
        df_final['ì£¼ë¬¸ìˆ˜ëŸ‰'] = pd.to_numeric(df_final['ì£¼ë¬¸ìˆ˜ëŸ‰'], errors='coerce').fillna(0).astype(int)
        smartstore_prices['ì£¼ë¬¸ìˆ˜ëŸ‰'] = pd.to_numeric(smartstore_prices['ì£¼ë¬¸ìˆ˜ëŸ‰'], errors='coerce').fillna(0).astype(int)
        godomall_prices['ì£¼ë¬¸ìˆ˜ëŸ‰'] = pd.to_numeric(godomall_prices['ì£¼ë¬¸ìˆ˜ëŸ‰'], errors='coerce').fillna(0).astype(int)
        
        df_final['ì‹¤ê²°ì œê¸ˆì•¡'] = pd.to_numeric(df_final['ì‹¤ê²°ì œê¸ˆì•¡'], errors='coerce').fillna(0).astype(int)
        
        # ë°ì´í„° ë³‘í•©
        df_final = pd.merge(df_final, smartstore_prices, on=key_cols_smartstore, how='left')
        df_final = pd.merge(df_final, godomall_prices, on=['ì¬ê³ ê´€ë¦¬ì½”ë“œ', 'ìˆ˜ë ¹ìëª…', 'ì£¼ë¬¸ìˆ˜ëŸ‰'], how='left')
        
        # ìµœì¢… ê¸ˆì•¡ ì—…ë°ì´íŠ¸
        df_final['ì‹¤ê²°ì œê¸ˆì•¡'] = np.where(
            df_final['ì‡¼í•‘ëª°'] == 'ê³ ë„ëª°5', 
            df_final['ìˆ˜ì •ë _ê¸ˆì•¡_ê³ ë„ëª°'].fillna(df_final['ì‹¤ê²°ì œê¸ˆì•¡']), 
            df_final['ì‹¤ê²°ì œê¸ˆì•¡']
        )
        df_final['ì‹¤ê²°ì œê¸ˆì•¡'] = np.where(
            df_final['ì‡¼í•‘ëª°'] == 'ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´', 
            df_final['ìˆ˜ì •ë _ê¸ˆì•¡_ìŠ¤í† ì–´'].fillna(df_final['ì‹¤ê²°ì œê¸ˆì•¡']), 
            df_final['ì‹¤ê²°ì œê¸ˆì•¡']
        )
        
        df_main_result = df_final[['ì¬ê³ ê´€ë¦¬ì½”ë“œ', 'SKUìƒí’ˆëª…', 'ì£¼ë¬¸ìˆ˜ëŸ‰', 'ì‹¤ê²°ì œê¸ˆì•¡', 'ì‡¼í•‘ëª°', 'ìˆ˜ë ¹ìëª…', 'original_order']]
        
        # ìˆ˜ëŸ‰ ìš”ì•½ ë° í¬ì¥ ë¦¬ìŠ¤íŠ¸
        df_quantity_summary = df_main_result.groupby('SKUìƒí’ˆëª…', as_index=False)['ì£¼ë¬¸ìˆ˜ëŸ‰'].sum().rename(columns={'ì£¼ë¬¸ìˆ˜ëŸ‰': 'ê°œìˆ˜'})
        
        df_packing_list = df_main_result.sort_values(by='original_order')[['SKUìƒí’ˆëª…', 'ì£¼ë¬¸ìˆ˜ëŸ‰', 'ìˆ˜ë ¹ìëª…', 'ì‡¼í•‘ëª°']].copy()
        is_first_item = df_packing_list['ìˆ˜ë ¹ìëª…'] != df_packing_list['ìˆ˜ë ¹ìëª…'].shift(1)
        df_packing_list['ë¬¶ìŒë²ˆí˜¸'] = is_first_item.cumsum()
        df_packing_list_final = df_packing_list.copy()
        df_packing_list_final['ë¬¶ìŒë²ˆí˜¸'] = df_packing_list_final['ë¬¶ìŒë²ˆí˜¸'].where(is_first_item, '')
        df_packing_list_final = df_packing_list_final[['ë¬¶ìŒë²ˆí˜¸', 'SKUìƒí’ˆëª…', 'ì£¼ë¬¸ìˆ˜ëŸ‰', 'ìˆ˜ë ¹ìëª…', 'ì‡¼í•‘ëª°']]
        
        # ë§ˆìŠ¤í„° ë°ì´í„° ë³‘í•©
        if df_master is not None and not df_master.empty:
            df_merged = pd.merge(df_main_result, df_master[['SKUì½”ë“œ', 'ê³¼ì„¸ì—¬ë¶€', 'ì…ìˆ˜ëŸ‰']], 
                                left_on='ì¬ê³ ê´€ë¦¬ì½”ë“œ', right_on='SKUì½”ë“œ', how='left')
        else:
            df_merged = df_main_result.copy()
            df_merged['ê³¼ì„¸ì—¬ë¶€'] = 'ê³¼ì„¸'
            df_merged['ì…ìˆ˜ëŸ‰'] = 1
            df_merged['SKUì½”ë“œ'] = df_merged['ì¬ê³ ê´€ë¦¬ì½”ë“œ']
        
        # ê±°ë˜ì²˜ ë§¤í•‘
        client_map = {
            'ì¿ íŒ¡': 'ì¿ íŒ¡ ì£¼ì‹íšŒì‚¬', 
            'ê³ ë„ëª°5': 'ê³ ë˜ë¯¸ìì‚¬ëª°_í˜„ê¸ˆì˜ìˆ˜ì¦(ê³ ë„ëª°)', 
            'ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´': 'ìŠ¤í† ì–´íŒœ',
            'ë°°ë¯¼ìƒíšŒ': 'ì£¼ì‹íšŒì‚¬ ìš°ì•„í•œí˜•ì œë“¤(ë°°ë¯¼ìƒíšŒ)',
            'ì´ì§€ì›°ëª°': 'ì£¼ì‹íšŒì‚¬ í˜„ëŒ€ì´ì§€ì›°'
        }
        
        # ì´ì¹´ìš´íŠ¸ ì—…ë¡œë“œìš© ë°ì´í„°
        df_ecount_upload = pd.DataFrame()
        
        df_ecount_upload['ì¼ì'] = datetime.now().strftime("%Y%m%d")
        df_ecount_upload['ê±°ë˜ì²˜ëª…'] = df_merged['ì‡¼í•‘ëª°'].map(client_map).fillna(df_merged['ì‡¼í•‘ëª°'])
        df_ecount_upload['ì¶œí•˜ì°½ê³ '] = 'ê³ ë˜ë¯¸'
        df_ecount_upload['ê±°ë˜ìœ í˜•'] = np.where(df_merged['ê³¼ì„¸ì—¬ë¶€'] == 'ë©´ì„¸', 12, 11)
        df_ecount_upload['ì ìš”_ì „í‘œ'] = 'ì˜¤ì „/ì˜¨ë¼ì¸'
        df_ecount_upload['í’ˆëª©ì½”ë“œ'] = df_merged['ì¬ê³ ê´€ë¦¬ì½”ë“œ']
        
        # ìˆ˜ëŸ‰ ê³„ì‚°
        is_box_order = df_merged['SKUìƒí’ˆëª…'].str.contains("BOX", na=False)
        ì…ìˆ˜ëŸ‰ = pd.to_numeric(df_merged['ì…ìˆ˜ëŸ‰'], errors='coerce').fillna(1)
        base_quantity = np.where(is_box_order, df_merged['ì£¼ë¬¸ìˆ˜ëŸ‰'] * ì…ìˆ˜ëŸ‰, df_merged['ì£¼ë¬¸ìˆ˜ëŸ‰'])
        is_3_pack = df_merged['SKUìƒí’ˆëª…'].str.contains("3ê°œì…|3ê°œ", na=False)
        final_quantity = np.where(is_3_pack, base_quantity * 3, base_quantity)
        df_ecount_upload['ë°•ìŠ¤'] = np.where(is_box_order, df_merged['ì£¼ë¬¸ìˆ˜ëŸ‰'], np.nan)
        df_ecount_upload['ìˆ˜ëŸ‰'] = final_quantity.astype(int)
        
        # ê¸ˆì•¡ ê³„ì‚°
        df_merged['ì‹¤ê²°ì œê¸ˆì•¡'] = pd.to_numeric(df_merged['ì‹¤ê²°ì œê¸ˆì•¡'], errors='coerce').fillna(0)
        ê³µê¸‰ê°€ì•¡ = np.where(df_merged['ê³¼ì„¸ì—¬ë¶€'] == 'ê³¼ì„¸', df_merged['ì‹¤ê²°ì œê¸ˆì•¡'] / 1.1, df_merged['ì‹¤ê²°ì œê¸ˆì•¡'])
        df_ecount_upload['ê³µê¸‰ê°€ì•¡'] = ê³µê¸‰ê°€ì•¡
        df_ecount_upload['ë¶€ê°€ì„¸'] = df_merged['ì‹¤ê²°ì œê¸ˆì•¡'] - df_ecount_upload['ê³µê¸‰ê°€ì•¡']
        
        df_ecount_upload['ì‡¼í•‘ëª°ê³ ê°ëª…'] = df_merged['ìˆ˜ë ¹ìëª…']
        df_ecount_upload['original_order'] = df_merged['original_order']
        
        # ì´ì¹´ìš´íŠ¸ ì»¬ëŸ¼ ì •ë¦¬
        ecount_columns = [
            'ì¼ì', 'ìˆœë²ˆ', 'ê±°ë˜ì²˜ì½”ë“œ', 'ê±°ë˜ì²˜ëª…', 'ë‹´ë‹¹ì', 'ì¶œí•˜ì°½ê³ ', 'ê±°ë˜ìœ í˜•', 'í†µí™”', 'í™˜ìœ¨', 
            'ì ìš”_ì „í‘œ', 'ë¯¸ìˆ˜ê¸ˆ', 'ì´í•©ê³„', 'ì—°ê²°ì „í‘œ', 'í’ˆëª©ì½”ë“œ', 'í’ˆëª©ëª…', 'ê·œê²©', 'ë°•ìŠ¤', 'ìˆ˜ëŸ‰', 
            'ë‹¨ê°€', 'ì™¸í™”ê¸ˆì•¡', 'ê³µê¸‰ê°€ì•¡', 'ë¶€ê°€ì„¸', 'ì ìš”_í’ˆëª©', 'ìƒì‚°ì „í‘œìƒì„±', 'ì‹œë¦¬ì–¼/ë¡œíŠ¸', 
            'ê´€ë¦¬í•­ëª©', 'ì‡¼í•‘ëª°ê³ ê°ëª…', 'original_order'
        ]
        
        for col in ecount_columns:
            if col not in df_ecount_upload:
                df_ecount_upload[col] = ''
        
        for col in ['ê³µê¸‰ê°€ì•¡', 'ë¶€ê°€ì„¸']:
            df_ecount_upload[col] = df_ecount_upload[col].round().astype('Int64')
        
        # ì •ë ¬
        sort_order = [
            'ê³ ë˜ë¯¸ìì‚¬ëª°_í˜„ê¸ˆì˜ìˆ˜ì¦(ê³ ë„ëª°)', 
            'ìŠ¤í† ì–´íŒœ', 
            'ì¿ íŒ¡ ì£¼ì‹íšŒì‚¬',
            'ì£¼ì‹íšŒì‚¬ ìš°ì•„í•œí˜•ì œë“¤(ë°°ë¯¼ìƒíšŒ)',
            'ì£¼ì‹íšŒì‚¬ í˜„ëŒ€ì´ì§€ì›°'
        ]
        
        df_ecount_upload['ê±°ë˜ì²˜ëª…_sort'] = pd.Categorical(
            df_ecount_upload['ê±°ë˜ì²˜ëª…'], 
            categories=sort_order, 
            ordered=True
        )
        
        df_ecount_upload = df_ecount_upload.sort_values(
            by=['ê±°ë˜ì²˜ëª…_sort', 'ê±°ë˜ìœ í˜•', 'original_order'],
            ascending=[True, True, True]
        ).drop(columns=['ê±°ë˜ì²˜ëª…_sort', 'original_order'])
        
        df_ecount_upload = df_ecount_upload[ecount_columns[:-1]]
        
        # ê¸°ë¡ìš© ë°ì´í„° ì¤€ë¹„
        df_for_record = df_merged.copy()
        df_for_record['ì£¼ë¬¸ì¼ì'] = order_date
        df_for_record['ê±°ë˜ì²˜ëª…'] = df_for_record['ì‡¼í•‘ëª°'].map(client_map).fillna(df_for_record['ì‡¼í•‘ëª°'])
        df_for_record['ê³µê¸‰ê°€ì•¡'] = ê³µê¸‰ê°€ì•¡.round().astype('Int64')
        df_for_record['ë¶€ê°€ì„¸'] = (df_merged['ì‹¤ê²°ì œê¸ˆì•¡'] - ê³µê¸‰ê°€ì•¡).round().astype('Int64')
        df_for_record['ê±°ë˜ìœ í˜•'] = np.where(df_merged['ê³¼ì„¸ì—¬ë¶€'] == 'ë©´ì„¸', 12, 11)
        df_for_record['í’ˆëª©ì½”ë“œ'] = df_merged['ì¬ê³ ê´€ë¦¬ì½”ë“œ']

        return (df_main_result.drop(columns=['original_order']), 
                df_quantity_summary, 
                df_packing_list_final, 
                df_ecount_upload, 
                df_for_record,
                True, 
                "ëª¨ë“  íŒŒì¼ ì²˜ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.", 
                warnings)

    except Exception as e:
        import traceback
        st.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        st.error(traceback.format_exc())
        return None, None, None, None, None, False, f"ì˜¤ë¥˜: {e}", []

# --------------------------------------------------------------------------
# ë©”ì¸ ì•±
# --------------------------------------------------------------------------
def main():
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.title("âš™ï¸ ì„¤ì •")
        
        user_name = st.text_input("ì‚¬ìš©ì ì´ë¦„", value=st.session_state.get('user_name', ''))
        if user_name:
            st.session_state['user_name'] = user_name
        
        st.divider()
        st.info("""
        **v2.0 Lite**
        - í•µì‹¬ ê¸°ëŠ¥ ìµœì í™”
        - ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„
        - ì•ˆì •ì ì¸ ì‘ë™
        """)
    
    # ë©”ì¸
    st.title("ğŸ“‘ ì£¼ë¬¸ ì²˜ë¦¬ ìë™í™” ì‹œìŠ¤í…œ v2.0 Lite")
    st.caption("ë¹ ë¥´ê³  ì•ˆì •ì ì¸ ì£¼ë¬¸ ë°ì´í„° ì²˜ë¦¬")
    
    # íƒ­
    tab1, tab2 = st.tabs(["ğŸ“¤ ë°ì´í„° ì²˜ë¦¬", "ğŸ“Š ê°„ë‹¨ ëŒ€ì‹œë³´ë“œ"])
    
    with tab1:
        st.header("1. ì›ë³¸ íŒŒì¼ ì—…ë¡œë“œ")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            file1 = st.file_uploader("ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´", type=['xlsx', 'xls'])
        with col2:
            file2 = st.file_uploader("ì´ì¹´ìš´íŠ¸", type=['xlsx', 'xls'])
        with col3:
            file3 = st.file_uploader("ê³ ë„ëª°", type=['xlsx', 'xls'])
        
        st.divider()
        
        if st.button("ğŸš€ ì²˜ë¦¬ ì‹œì‘", type="primary", use_container_width=True):
            if file1 and file2 and file3:
                # ë§ˆìŠ¤í„° ë°ì´í„° ë¡œë“œ
                with st.spinner('ë§ˆìŠ¤í„° ë°ì´í„° ë¡œë“œ ì¤‘...'):
                    df_master = load_master_from_sharepoint()
                
                if df_master is None:
                    st.error("ë§ˆìŠ¤í„° ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨!")
                    return
                
                # íŒŒì¼ ì²˜ë¦¬
                with st.spinner('íŒŒì¼ ì²˜ë¦¬ ì¤‘...'):
                    result = process_all_files(file1, file2, file3, df_master)
                
                if result[5]:  # success
                    df_main, df_qty, df_pack, df_ecount, df_for_record, success, message, warnings = result
                    
                    st.success(message)
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    
                    # ë¡œì»¬ ì €ì¥
                    saved, count = save_record_locally(df_for_record)
                    if saved:
                        st.info(f"âœ… {count}ê±´ ì €ì¥ ì™„ë£Œ")
                    
                    # ê²½ê³ 
                    if warnings:
                        with st.expander("âš ï¸ ê²½ê³  ë©”ì‹œì§€"):
                            for w in warnings:
                                st.write(w)
                    
                    # ê²°ê³¼ í‘œì‹œ
                    st.subheader("ğŸ“¥ ë‹¤ìš´ë¡œë“œ")
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.download_button(
                            "ğŸ“¥ ì´ì¹´ìš´íŠ¸ ì—…ë¡œë“œìš©",
                            to_excel_formatted(df_ecount, 'ecount_upload'),
                            f"ecount_{timestamp}.xlsx"
                        )
                        st.download_button(
                            "ğŸ“¥ í¬ì¥ ë¦¬ìŠ¤íŠ¸",
                            to_excel_formatted(df_pack, 'packing_list'),
                            f"packing_{timestamp}.xlsx"
                        )
                    
                    with col2:
                        st.download_button(
                            "ğŸ“¥ ì¶œê³  ìˆ˜ëŸ‰",
                            to_excel_formatted(df_qty, 'quantity_summary'),
                            f"quantity_{timestamp}.xlsx"
                        )
                        st.download_button(
                            "ğŸ“¥ ìµœì¢… ë³´ì • ë¦¬ìŠ¤íŠ¸",
                            to_excel_formatted(df_main),
                            f"final_{timestamp}.xlsx"
                        )
                    
                    # ë¯¸ë¦¬ë³´ê¸°
                    with st.expander("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
                        st.dataframe(df_ecount.head(10))
                else:
                    st.error(result[6])
            else:
                st.warning("3ê°œ íŒŒì¼ì„ ëª¨ë‘ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    
    with tab2:
        st.header("ğŸ“Š ê°„ë‹¨ ëŒ€ì‹œë³´ë“œ")
        
        df_record = load_record_data()
        
        if not df_record.empty:
            create_simple_dashboard(df_record)
            
            # AI ë¶„ì„ (ì˜µì…˜)
            if st.button("ğŸ¤– AI ë¶„ì„"):
                with st.spinner("ë¶„ì„ ì¤‘..."):
                    analysis = analyze_with_gemini(df_record, "trend")
                    st.write(analysis)
        else:
            st.info("ì•„ì§ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
